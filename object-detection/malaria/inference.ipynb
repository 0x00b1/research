{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import keras.backend\n",
    "import keras.engine.topology\n",
    "import keras.layers\n",
    "import keras.models\n",
    "import keras_tqdm\n",
    "import layers\n",
    "import math\n",
    "import numpy\n",
    "import os\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import sys\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "configuration = tensorflow.ConfigProto()\n",
    "\n",
    "configuration.gpu_options.allow_growth = True\n",
    "\n",
    "configuration.gpu_options.visible_device_list = \"1\"\n",
    "\n",
    "session = tensorflow.Session(config=configuration)\n",
    "\n",
    "keras.backend.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def identity_block(input_tensor, kernel_size, filters, stage, block, trainable=True): \n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "\n",
    "    if keras.backend.image_dim_ordering() == 'tf':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = keras.layers.Convolution2D(nb_filter1, (1, 1),\n",
    "                                   name=conv_name_base + '2a',\n",
    "                                   trainable=trainable)(input_tensor)\n",
    "    x = layers.BatchNormalization(trainable=False, axis=bn_axis,\n",
    "                                        name=bn_name_base + '2a')(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = keras.layers.Convolution2D(nb_filter2, (kernel_size, kernel_size),\n",
    "                                   padding='same',\n",
    "                                   name=conv_name_base + '2b',\n",
    "                                   trainable=trainable)(x)\n",
    "    x = layers.BatchNormalization(trainable=False, axis=bn_axis,\n",
    "                                        name=bn_name_base + '2b')(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = keras.layers.Convolution2D(nb_filter3, (1, 1),\n",
    "                                   name=conv_name_base + '2c',\n",
    "                                   trainable=trainable)(x)\n",
    "    x = layers.BatchNormalization(trainable=False, axis=bn_axis,\n",
    "                                        name=bn_name_base + '2c')(x)\n",
    "\n",
    "    x = keras.layers.merge([x, input_tensor], mode='sum')\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def identity_block_td(input_tensor, kernel_size, filters, stage, block,\n",
    "                      trainable=True):\n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "    if keras.backend.image_dim_ordering() == 'tf':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = keras.layers.TimeDistributed(\n",
    "        keras.layers.Convolution2D(nb_filter1, (1, 1), trainable=trainable,\n",
    "                                   kernel_initializer='normal'),\n",
    "        name=conv_name_base + '2a')(input_tensor)\n",
    "    x = keras.layers.TimeDistributed(\n",
    "        layers.BatchNormalization(trainable=False, axis=bn_axis),\n",
    "        name=bn_name_base + '2a')(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = keras.layers.TimeDistributed(\n",
    "        keras.layers.Convolution2D(nb_filter2, (kernel_size, kernel_size),\n",
    "                                   trainable=trainable,\n",
    "                                   kernel_initializer='normal',\n",
    "                                   padding='same'),\n",
    "        name=conv_name_base + '2b')(x)\n",
    "    x = keras.layers.TimeDistributed(\n",
    "        layers.BatchNormalization(trainable=False, axis=bn_axis),\n",
    "        name=bn_name_base + '2b')(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = keras.layers.TimeDistributed(\n",
    "        keras.layers.Convolution2D(nb_filter3, (1, 1), trainable=trainable,\n",
    "                                   kernel_initializer='normal'),\n",
    "        name=conv_name_base + '2c')(x)\n",
    "    x = keras.layers.TimeDistributed(\n",
    "        layers.BatchNormalization(trainable=False, axis=bn_axis),\n",
    "        name=bn_name_base + '2c')(x)\n",
    "\n",
    "    x = keras.layers.merge([x, input_tensor], mode='sum')\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, stage, block,\n",
    "               strides=(2, 2), trainable=True):\n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "    if keras.backend.image_dim_ordering() == 'tf':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = keras.layers.Convolution2D(nb_filter1, (1, 1), strides=strides,\n",
    "                                   name=conv_name_base + '2a',\n",
    "                                   trainable=trainable)(\n",
    "        input_tensor)\n",
    "    x = layers.BatchNormalization(trainable=False, axis=bn_axis,\n",
    "                                        name=bn_name_base + '2a')(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = keras.layers.Convolution2D(nb_filter2, (kernel_size, kernel_size),\n",
    "                                   padding='same',\n",
    "                                   name=conv_name_base + '2b',\n",
    "                                   trainable=trainable)(x)\n",
    "    x = layers.BatchNormalization(trainable=False, axis=bn_axis,\n",
    "                                        name=bn_name_base + '2b')(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = keras.layers.Convolution2D(nb_filter3, (1, 1),\n",
    "                                   name=conv_name_base + '2c',\n",
    "                                   trainable=trainable)(x)\n",
    "    x = layers.BatchNormalization(trainable=False, axis=bn_axis,\n",
    "                                        name=bn_name_base + '2c')(x)\n",
    "\n",
    "    shortcut = keras.layers.Convolution2D(nb_filter3, (1, 1), strides=strides,\n",
    "                                          name=conv_name_base + '1',\n",
    "                                          trainable=trainable)(\n",
    "        input_tensor)\n",
    "    shortcut = layers.BatchNormalization(trainable=False, axis=bn_axis,\n",
    "                                               name=bn_name_base + '1')(\n",
    "        shortcut)\n",
    "\n",
    "    x = keras.layers.merge([x, shortcut], mode='sum')\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_block_td(input_tensor, kernel_size, filters, stage, block,\n",
    "                  strides=(2, 2), trainable=True):\n",
    "    \"\"\"conv_block is the block that has a conv layer at shortcut\n",
    "    # Arguments\n",
    "            input_tensor: input tensor\n",
    "            kernel_size: defualt 3, the kernel size of middle conv layer at main path\n",
    "            filters: list of integers, the nb_filters of 3 conv layer at main path\n",
    "            stage: integer, current stage label, used for generating layer names\n",
    "            block: 'a','b'..., current block label, used for generating layer names\n",
    "    Note that from stage 3, the first conv layer at main path is with strides=(2,2)\n",
    "    And the shortcut should have strides=(2,2) as well\n",
    "    \"\"\"\n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "    if keras.backend.image_dim_ordering() == 'tf':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = keras.layers.TimeDistributed(\n",
    "        keras.layers.Convolution2D(nb_filter1, (1, 1), strides=strides,\n",
    "                                   trainable=trainable,\n",
    "                                   kernel_initializer='normal'),\n",
    "        name=conv_name_base + '2a')(input_tensor)\n",
    "    x = keras.layers.TimeDistributed(\n",
    "        layers.BatchNormalization(trainable=False, axis=bn_axis),\n",
    "        name=bn_name_base + '2a')(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = keras.layers.TimeDistributed(\n",
    "        keras.layers.Convolution2D(nb_filter2, (kernel_size, kernel_size),\n",
    "                                   padding='same',\n",
    "                                   trainable=trainable,\n",
    "                                   kernel_initializer='normal'),\n",
    "        name=conv_name_base + '2b')(x)\n",
    "    x = keras.layers.TimeDistributed(\n",
    "        layers.BatchNormalization(trainable=False, axis=bn_axis),\n",
    "        name=bn_name_base + '2b')(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = keras.layers.TimeDistributed(\n",
    "        keras.layers.Convolution2D(nb_filter3, (1, 1),\n",
    "                                   kernel_initializer='normal'),\n",
    "        name=conv_name_base + '2c', trainable=trainable)(x)\n",
    "    x = keras.layers.TimeDistributed(\n",
    "        layers.BatchNormalization(trainable=False, axis=bn_axis),\n",
    "        name=bn_name_base + '2c')(x)\n",
    "\n",
    "    shortcut = keras.layers.TimeDistributed(\n",
    "        keras.layers.Convolution2D(nb_filter3, (1, 1), strides=strides,\n",
    "                                   trainable=trainable,\n",
    "                                   kernel_initializer='normal'),\n",
    "        name=conv_name_base + '1')(\n",
    "        input_tensor)\n",
    "    shortcut = keras.layers.TimeDistributed(\n",
    "        layers.BatchNormalization(trainable=False, axis=bn_axis),\n",
    "        name=bn_name_base + '1')(shortcut)\n",
    "\n",
    "    x = keras.layers.merge([x, shortcut], mode='sum')\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def nn_base(input_tensor=None, trainable=False):\n",
    "    # Determine proper input shape\n",
    "    if keras.backend.image_dim_ordering() == 'th':\n",
    "        input_shape = (3, None, None)\n",
    "    else:\n",
    "        input_shape = (None, None, 3)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = keras.layers.Input(shape=input_shape)\n",
    "    else:\n",
    "        if not keras.backend.is_keras_tensor(input_tensor):\n",
    "            img_input = keras.layers.Input(tensor=input_tensor,\n",
    "                                           shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    if keras.backend.image_dim_ordering() == 'tf':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "\n",
    "    x = keras.layers.ZeroPadding2D((3, 3))(img_input)\n",
    "\n",
    "    x = keras.layers.Convolution2D(64, (7, 7), strides=(2, 2), name='conv1',\n",
    "                                   trainable=trainable)(x)\n",
    "    x = layers.BatchNormalization(trainable=False, axis=bn_axis,\n",
    "                                        name='bn_conv1')(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1),\n",
    "                   trainable=trainable)\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b',\n",
    "                       trainable=trainable)\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c',\n",
    "                       trainable=trainable)\n",
    "\n",
    "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a',\n",
    "                   trainable=trainable)\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b',\n",
    "                       trainable=trainable)\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c',\n",
    "                       trainable=trainable)\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d',\n",
    "                       trainable=trainable)\n",
    "\n",
    "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a',\n",
    "                   trainable=trainable)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b',\n",
    "                       trainable=trainable)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c',\n",
    "                       trainable=trainable)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d',\n",
    "                       trainable=trainable)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e',\n",
    "                       trainable=trainable)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f',\n",
    "                       trainable=trainable)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def classifier_layers(x, trainable=False):\n",
    "    x = conv_block_td(x, 3, [512, 512, 2048], stage=5, block='a',\n",
    "                      strides=(1, 1), trainable=trainable)\n",
    "    x = identity_block_td(x, 3, [512, 512, 2048], stage=5, block='b',\n",
    "                          trainable=trainable)\n",
    "    x = identity_block_td(x, 3, [512, 512, 2048], stage=5, block='c',\n",
    "                          trainable=trainable)\n",
    "    x = keras.layers.TimeDistributed(keras.layers.AveragePooling2D((7, 7)),\n",
    "                                     name='avg_pool')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def _rpn(base_layers, num_anchors):\n",
    "    x = keras.layers.Convolution2D(512, (3, 3), padding='same',\n",
    "                                   activation='relu',\n",
    "                                   kernel_initializer='normal',\n",
    "                                   name='rpn_conv1')(\n",
    "        base_layers)\n",
    "\n",
    "    x_class = keras.layers.Convolution2D(num_anchors, (1, 1),\n",
    "                                         activation='sigmoid',\n",
    "                                         kernel_initializer='uniform',\n",
    "                                         name='rpn_out_class')(x)\n",
    "    x_regr = keras.layers.Convolution2D(num_anchors * 4, (1, 1),\n",
    "                                        activation='linear',\n",
    "                                        kernel_initializer='normal',\n",
    "                                        name='rpn_out_regress')(x)\n",
    "\n",
    "    return [x_class, x_regr]\n",
    "\n",
    "\n",
    "def _classifier(base_layers, input_rois, num_rois, nb_classes=21):\n",
    "    pooling_regions = 7\n",
    "\n",
    "    out_roi_pool = layers.ROI(pooling_regions, num_rois)(\n",
    "        [base_layers, input_rois])\n",
    "\n",
    "    out = classifier_layers(out_roi_pool, trainable=True)\n",
    "\n",
    "    out = keras.layers.TimeDistributed(keras.layers.Flatten(),\n",
    "                                       name='td_flatten')(out)\n",
    "\n",
    "    out_class = keras.layers.TimeDistributed(\n",
    "        keras.layers.Dense(nb_classes, activation='softmax',\n",
    "                           kernel_initializer='zero'),\n",
    "        name='dense_class_{}'.format(nb_classes))(out)\n",
    "    # note: no regression target for bg class\n",
    "    out_regr = keras.layers.TimeDistributed(\n",
    "        keras.layers.Dense(4 * (nb_classes - 1), activation='linear',\n",
    "                           kernel_initializer='zero'),\n",
    "        name='dense_regress_{}'.format(nb_classes))(out)\n",
    "\n",
    "    return [out_class, out_regr]\n",
    "\n",
    "\n",
    "def apply_regr(x, y, w, h, tx, ty, tw, th):\n",
    "    try:\n",
    "        cx = x + w / 2.\n",
    "        cy = y + h / 2.\n",
    "        cx1 = tx * w + cx\n",
    "        cy1 = ty * h + cy\n",
    "        w1 = math.exp(tw) * w\n",
    "        h1 = math.exp(th) * h\n",
    "        x1 = cx1 - w1 / 2.\n",
    "        y1 = cy1 - h1 / 2.\n",
    "        x1 = int(round(x1))\n",
    "        y1 = int(round(y1))\n",
    "        w1 = int(round(w1))\n",
    "        h1 = int(round(h1))\n",
    "\n",
    "        return x1, y1, w1, h1\n",
    "\n",
    "    except ValueError:\n",
    "        return x, y, w, h\n",
    "    except OverflowError:\n",
    "        return x, y, w, h\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return x, y, w, h\n",
    "\n",
    "\n",
    "def non_max_suppression_fast(boxes, probs, threshold=0.95):\n",
    "    # if there are no boxes, return an empty list\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "\n",
    "    # grab the coordinates of the bounding boxes\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "\n",
    "    numpy.testing.assert_array_less(x1, x2)\n",
    "    numpy.testing.assert_array_less(y1, y2)\n",
    "\n",
    "    # if the bounding boxes integers, convert them to floats --\n",
    "    # this is important since we'll be doing a bunch of divisions\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    "\n",
    "    # initialize the list of picked indexes\n",
    "    pick = []\n",
    "\n",
    "    # sort the bounding boxes\n",
    "    idxs = numpy.argsort(probs)\n",
    "\n",
    "    # keep looping while some indexes still remain in the indexes\n",
    "    # list\n",
    "    while len(idxs) > 0:\n",
    "        # grab the last index in the indexes list and add the\n",
    "        # index value to the list of picked indexes\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "\n",
    "        # find the intersection\n",
    "\n",
    "        xx1_int = numpy.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1_int = numpy.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2_int = numpy.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2_int = numpy.minimum(y2[i], y2[idxs[:last]])\n",
    "\n",
    "        # find the union\n",
    "        xx1_un = numpy.minimum(x1[i], x1[idxs[:last]])\n",
    "        yy1_un = numpy.minimum(y1[i], y1[idxs[:last]])\n",
    "        xx2_un = numpy.maximum(x2[i], x2[idxs[:last]])\n",
    "        yy2_un = numpy.maximum(y2[i], y2[idxs[:last]])\n",
    "\n",
    "        # compute the width and height of the bounding box\n",
    "        ww_int = xx2_int - xx1_int\n",
    "        hh_int = yy2_int - yy1_int\n",
    "\n",
    "        ww_un = xx2_un - xx1_un\n",
    "        hh_un = yy2_un - yy1_un\n",
    "\n",
    "        ww_un = numpy.maximum(0, ww_un)\n",
    "        hh_un = numpy.maximum(0, hh_un)\n",
    "\n",
    "        # compute the ratio of overlap\n",
    "        overlap = (ww_int * hh_int) / (ww_un * hh_un + 1e-9)\n",
    "\n",
    "        # delete all indexes from the index list that have\n",
    "        idxs = numpy.delete(idxs, numpy.concatenate(([last],\n",
    "                                                     numpy.where(\n",
    "                                                         overlap > threshold)[\n",
    "                                                         0])))\n",
    "\n",
    "        if len(pick) >= 300:\n",
    "            break\n",
    "\n",
    "            # return only the bounding boxes that were picked using the\n",
    "            # integer data type\n",
    "    boxes = boxes[pick].astype(\"int\")\n",
    "    probs = probs[pick]\n",
    "    return boxes, probs\n",
    "\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        # setting for data augmentation\n",
    "        self.use_horizontal_flips = False\n",
    "        self.use_vertical_flips = False\n",
    "        self.scale_augment = False\n",
    "        self.random_rotate = False\n",
    "        self.random_rotate_scale = 180.\n",
    "\n",
    "        # anchor box scales\n",
    "        self.anchor_box_scales = [128, 256, 512]\n",
    "\n",
    "        # anchor box ratios\n",
    "        self.anchor_box_ratios = [[1, 1], [1, 2], [2, 1]]\n",
    "\n",
    "        # size to resize the smallest side of the image\n",
    "        self.im_size = 600\n",
    "\n",
    "        # number of ROIs at once\n",
    "        self.num_rois = 2\n",
    "\n",
    "        # stride at the RPN (this depends on the network configuration)\n",
    "        self.rpn_stride = 16\n",
    "\n",
    "        self.balanced_classes = False\n",
    "\n",
    "        # scaling the stdev\n",
    "        self.std_scaling = 4.0\n",
    "\n",
    "        # overlaps for RPN\n",
    "        self.rpn_min_overlap = 0.3\n",
    "        self.rpn_max_overlap = 0.7\n",
    "\n",
    "        # overlaps for classifier ROIs\n",
    "        self.classifier_min_overlap = 0.1\n",
    "        self.classifier_max_overlap = 0.5\n",
    "\n",
    "        if keras.backend.image_dim_ordering() == 'th':\n",
    "            weights = 'resnet50_weights_th_dim_ordering_th_kernels_notop.h5'\n",
    "\n",
    "            self.base_net_weights = weights\n",
    "        else:\n",
    "            weights = 'resnet50_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "\n",
    "            self.base_net_weights = weights\n",
    "\n",
    "        self.model_path = 'model_frcnn.hdf5'\n",
    "\n",
    "\n",
    "sys.setrecursionlimit(40000)\n",
    "C = Config()\n",
    "C.use_horizontal_flips = False\n",
    "C.use_vertical_flips = False\n",
    "\n",
    "\n",
    "def format_img(img):\n",
    "    img_min_side = 600.0\n",
    "    (height, width, _) = img.shape\n",
    "\n",
    "    if width <= height:\n",
    "        f = img_min_side / width\n",
    "        new_height = int(f * height)\n",
    "        new_width = int(img_min_side)\n",
    "    else:\n",
    "        f = img_min_side / height\n",
    "        new_width = int(f * width)\n",
    "        new_height = int(img_min_side)\n",
    "\n",
    "    img = skimage.transform.resize(img, (new_width, new_height))\n",
    "    img = img[:, :, (2, 1, 0)]\n",
    "    img = numpy.transpose(img, (2, 0, 1)).astype(numpy.float32)\n",
    "    img = numpy.expand_dims(img, axis=0)\n",
    "    img[:, 0, :, :] -= 103.939\n",
    "    img[:, 1, :, :] -= 116.779\n",
    "    img[:, 2, :, :] -= 123.68\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def rpn_to_roi(rpn_layer, regr_layer, C, dim_ordering, use_regr = True):\n",
    "    regr_layer = regr_layer / C.std_scaling\n",
    "\n",
    "    anchor_sizes = C.anchor_box_scales\n",
    "    anchor_ratios = C.anchor_box_ratios\n",
    "\n",
    "    assert rpn_layer.shape[0] == 1\n",
    "\n",
    "    all_boxes = []\n",
    "    all_probs = []\n",
    "    if dim_ordering == 'th':\n",
    "        (rows,cols) = rpn_layer.shape[2:]\n",
    "    elif dim_ordering == 'tf':\n",
    "        (rows, cols) = rpn_layer.shape[1:3]\n",
    "    curr_layer = 0\n",
    "\n",
    "    for anchor_size in anchor_sizes:\n",
    "        for anchor_ratio in anchor_ratios:\n",
    "\n",
    "            anchor_x = (anchor_size * anchor_ratio[0])/C.rpn_stride\n",
    "            anchor_y = (anchor_size * anchor_ratio[1])/C.rpn_stride\n",
    "            if dim_ordering == 'th':\n",
    "                rpn = rpn_layer[0, curr_layer, :, :]\n",
    "                regr = regr_layer[0, 4 * curr_layer:4 * curr_layer + 4, :, :]\n",
    "            else:\n",
    "                rpn = rpn_layer[0, :, :, curr_layer]\n",
    "                regr = np.copy(regr_layer[0, :, :, 4 * curr_layer:4 * curr_layer + 4])\n",
    "                regr = np.transpose(regr,(2,0,1))\n",
    "\n",
    "            curr_layer += 1\n",
    "            for jy in range(rows):\n",
    "                for ix in range(cols):\n",
    "                    if rpn[jy,ix] > 0.50:\n",
    "                        (tx, ty, tw, th) = regr[:, jy, ix]\n",
    "\n",
    "                        x1 = ix - anchor_x/2\n",
    "                        y1 = jy - anchor_y/2\n",
    "\n",
    "                        w = anchor_x\n",
    "                        h = anchor_y\n",
    "\n",
    "                        if use_regr:\n",
    "                            (x1, y1, w, h) = apply_regr(x1, y1, w, h, tx, ty, tw, th)\n",
    "\n",
    "                        w = max(4, w)\n",
    "                        h = max(4, h)\n",
    "\n",
    "                        x2 = x1 + w\n",
    "                        y2 = y1 + h\n",
    "\n",
    "                        # box must start inside image\n",
    "                        x1 = max(x1, 0)\n",
    "                        y1 = max(y1, 0)\n",
    "                        \n",
    "                        #box must end inside image\n",
    "                        x2 = min(x2, cols-1)\n",
    "                        y2 = min(y2, rows-1)\n",
    "                        \n",
    "                        if x2 - x1 < 1:\n",
    "                            continue\n",
    "                        if y2 - y1 < 1:\n",
    "                            continue\n",
    "\n",
    "                        all_boxes.append((x1, y1, x2, y2))\n",
    "                        all_probs.append(rpn[jy, ix])\n",
    "\n",
    "    all_boxes = np.array(all_boxes)\n",
    "    all_probs = np.array(all_probs)\n",
    "    \n",
    "    print(all_probs)\n",
    "\n",
    "    return non_max_suppression_fast(all_boxes, all_probs, 0.7)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('/home/jhung0/classes.json', 'r') as class_data_json:\n",
    "    class_mapping = json.load(class_data_json)\n",
    "\n",
    "if 'bg' not in class_mapping:\n",
    "    class_mapping['bg'] = len(class_mapping)\n",
    "\n",
    "class_mapping = {v: k for k, v in class_mapping.items()}\n",
    "\n",
    "class_to_color = {class_mapping[v]: numpy.random.randint(0, 255, 3) for v\n",
    "                  in class_mapping}\n",
    "num_rois = 16\n",
    "\n",
    "if keras.backend.image_dim_ordering() == 'th':\n",
    "    input_shape_img = (3, None, None)\n",
    "    input_shape_features = (1024, None, None)\n",
    "else:\n",
    "    input_shape_img = (None, None, 3)\n",
    "    input_shape_features = (None, None, 1024)\n",
    "\n",
    "img_input = keras.layers.Input(shape=input_shape_img)\n",
    "\n",
    "feature_map_input = keras.layers.Input(shape=input_shape_features)\n",
    "\n",
    "roi_input = keras.layers.Input(shape=(num_rois, 4))\n",
    "\n",
    "# define the base network (resnet here, can be VGG, Inception, etc)\n",
    "shared_layers = nn_base(img_input)\n",
    "\n",
    "# define the RPN, built on the base layers\n",
    "num_anchors = len(C.anchor_box_scales) * len(C.anchor_box_ratios)\n",
    "\n",
    "rpn = _rpn(shared_layers, num_anchors)\n",
    "\n",
    "# classifier, uses base layers + proposals\n",
    "print(class_mapping)\n",
    "\n",
    "classifier = _classifier(feature_map_input, roi_input, num_rois,\n",
    "                         nb_classes=len(class_mapping))\n",
    "\n",
    "model_rpn = keras.models.Model(img_input, rpn + [shared_layers])\n",
    "\n",
    "model_classifier = keras.models.Model([feature_map_input, roi_input], classifier)\n",
    "\n",
    "weights_path = '/home/0x00b1/object-detection/model.hdf5'\n",
    "\n",
    "model_rpn.load_weights(weights_path, by_name=True)\n",
    "\n",
    "model_classifier.load_weights(weights_path, by_name=True)\n",
    "\n",
    "model_rpn.compile(optimizer='sgd', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%time model_classifier.compile(optimizer='sgd', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "img_path = \"/home/jhung0/training/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for _, img_name in enumerate(sorted(os.listdir(img_path))[:1]):\n",
    "    print(img_name)\n",
    "    filepath = os.path.join(img_path, img_name)\n",
    "    img = skimage.io.imread(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = format_img(img)\n",
    "\n",
    "img_scaled = numpy.transpose(X[0, (2, 1, 0), :, :], (1, 2, 0)).copy()\n",
    "img_scaled[:, :, 0] += 123.68\n",
    "img_scaled[:, :, 1] += 116.779\n",
    "img_scaled[:, :, 2] += 103.939\n",
    "\n",
    "img_scaled = img_scaled.astype(numpy.uint8)\n",
    "\n",
    "if keras.backend.image_dim_ordering() == 'tf':\n",
    "    X = numpy.transpose(X, (0, 2, 3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# get the feature maps and output from the RPN\n",
    "%time [Y1, Y2, F] = model_rpn.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "R = rpn_to_roi(Y1, Y2, C, keras.backend.image_dim_ordering(), 0.7)\n",
    "\n",
    "# convert from (x1,y1,x2,y2) to (x,y,w,h)\n",
    "R[:, 2] = R[:, 2] - R[:, 0]\n",
    "R[:, 3] = R[:, 3] - R[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# apply the spatial pyramid pooling to the proposed regions\n",
    "bboxes = {}\n",
    "probs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot\n",
    "import matplotlib.patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figure = matplotlib.pyplot.figure(figsize=(12, 8))\n",
    "\n",
    "axis = figure.add_subplot(111, aspect=\"equal\")\n",
    "\n",
    "for region in R:\n",
    "    patch = matplotlib.patches.Rectangle((region[0], region[1]), region[2], region[3], fill=False)\n",
    "\n",
    "    axis.add_patch(patch)\n",
    "\n",
    "axis.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ROIs = np.expand_dims(R[num_rois*jk:num_rois*(jk+1),:],axis=0)\n",
    "\n",
    "# if ROIs.shape[1] == 0:\n",
    "#     break\n",
    "\n",
    "if jk == R.shape[0]//num_rois:\n",
    "    #pad R\n",
    "    curr_shape = ROIs.shape\n",
    "    target_shape = (curr_shape[0],num_rois,curr_shape[2])\n",
    "    ROIs_padded = np.zeros(target_shape).astype(ROIs.dtype)\n",
    "    ROIs_padded[:,:curr_shape[1],:] = ROIs\n",
    "    ROIs_padded[0,curr_shape[1]:,:] = ROIs[0,0,:]\n",
    "    ROIs = ROIs_padded\n",
    "\n",
    "[P_cls, P_regr] = model_classifier.predict([F, ROIs])\n",
    "\n",
    "P_regr = P_regr / C.std_scaling\n",
    "\n",
    "for ii in range(P_cls.shape[1]):\n",
    "    if np.max(P_cls[0,ii,:]) < 0.5:\n",
    "        continue\n",
    "\n",
    "    if np.argmax(P_cls[0,ii,:]) == (P_cls.shape[2] - 1):\n",
    "        continue\n",
    "\n",
    "    cls_name = class_mapping[np.argmax(P_cls[0,ii,:])]\n",
    "\n",
    "    if cls_name not in bboxes:\n",
    "        bboxes[cls_name] = []\n",
    "        probs[cls_name] = []\n",
    "\n",
    "    (x, y, w, h) = ROIs[0,ii,:]\n",
    "\n",
    "    cls_num = np.argmax(P_cls[0, ii, :])\n",
    "    \n",
    "    print(ii)\n",
    "    \n",
    "    try:\n",
    "        (tx, ty, tw, th) = P_regr[0, ii, 4*cls_num:4*(cls_num+1)]\n",
    "    \n",
    "        x, y, w, h = roi_helpers.apply_regr(x, y, w, h, tx, ty, tw, th)\n",
    "\n",
    "        bboxes[cls_name].append([16*x, 16*y, 16*(x+w), 16*(y+h)])\n",
    "        probs[cls_name].append(np.max(P_cls[0, ii, :]))\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.max(P_cls[0, ii, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(P_cls.shape[2] - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.argmax(P_cls[0, ii, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "all_dets = {}\n",
    "\n",
    "for key in bboxes:\n",
    "    bbox = np.array(bboxes[key])\n",
    "\n",
    "#     new_boxes, new_probs = non_max_suppression_fast(bbox, np.array(probs[key]), threshold=0.5)\n",
    "    \n",
    "#     for jk in range(new_boxes.shape[0]):\n",
    "#         (x1,y1,x2,y2) = new_boxes[jk,:]\n",
    "\n",
    "#         cv2.rectangle(img_scaled,(x1, y1), (x2, y2), class_to_color[key],2)\n",
    "\n",
    "#         textLabel = '{}:{}'.format(key,int(100*new_probs[jk]))\n",
    "#         if key not in all_dets:\n",
    "#             all_dets[key] = 100*new_probs[jk]\n",
    "#         else:\n",
    "#             all_dets[key] = max(all_dets[key],100*new_probs[jk])\n",
    "\n",
    "#         (retval,baseLine) = cv2.getTextSize(textLabel,cv2.FONT_HERSHEY_COMPLEX,1,1)\n",
    "#         textOrg = (x1,y1+20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
